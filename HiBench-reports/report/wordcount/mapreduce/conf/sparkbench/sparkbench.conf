# Source: /home/hduser/HiBench/conf/00-default-properties.conf
hibench.bayes.dir.name.input	Input
hibench.bayes.dir.name.output	Output
hibench.compress.codec	org.apache.hadoop.io.compress.SnappyCodec
hibench.compress.codec.map	org.apache.hadoop.io.compress.SnappyCodec
hibench.compress.default.codec	org.apache.hadoop.io.compress.DefaultCodec
hibench.compress.lzo.codec	com.hadoop.compression.lzo.LzoCodec
hibench.compress.map.output.compress.codec.hadoop1.name	mapred.map.output.compress.codec
hibench.compress.map.output.compress.codec.hadoop2.name	mapreduce.map.output.compress.codec
hibench.compress.map.output.compress.codec.name	mapreduce.map.output.compress.codec
hibench.compress.map.output.compress.codec.value	org.apache.hadoop.io.compress.SnappyCodec
hibench.compress.map.output.compress.hadoop1.name	mapred.map.output.compress
hibench.compress.map.output.compress.hadoop2.name	mapreduce.map.output.compress
hibench.compress.map.output.compress.name	mapreduce.map.output.compress
hibench.compress.output.fileoutputformat.compress.codec.hadoop1.name	mapred.output.compression.codec
hibench.compress.output.fileoutputformat.compress.codec.hadoop2.name	mapreduce.output.fileoutputformat.compress.codec
hibench.compress.output.fileoutputformat.compress.codec.name	mapreduce.output.fileoutputformat.compress.codec
hibench.compress.output.fileoutputformat.compress.codec.value	org.apache.hadoop.io.compress.SnappyCodec
hibench.compress.output.fileoutputformat.compress.hadoop1.name	mapred.output.compress
hibench.compress.output.fileoutputformat.compress.hadoop2.name	mapreduce.output.fileoutputformat.compress
hibench.compress.output.fileoutputformat.compress.name	mapreduce.output.fileoutputformat.compress
hibench.compress.output.fileoutputformat.compress.type.hadoop1.name	mapred.output.compression.type
hibench.compress.output.fileoutputformat.compress.type.hadoop2.name	mapreduce.output.fileoutputformat.compress.type
hibench.compress.output.fileoutputformat.compress.type.name	mapreduce.output.fileoutputformat.compress.type
hibench.compress.snappy.codec	org.apache.hadoop.io.compress.SnappyCodec
hibench.configure.dir	/home/hduser/HiBench/conf
hibench.consts.mr.hadoop1	MR1
hibench.consts.mr.hadoop2	MR2
hibench.dependency.dir	/home/hduser/HiBench/src
hibench.dfsioe.dir.name.input	Input
hibench.dfsioe.dir.name.output	Output
hibench.hadoop.executable	/usr/local/hadoop/bin/hadoop
hibench.hadoop.mapreduce.home	/usr/local/hadoop
hibench.hadoop.version.mr	MR2
hibench.hdfs.data.dir	hdfs://master:54310/HiBench
hibench.hibench.datatool.dir	/home/hduser/HiBench/src/autogen/target/autogen-5.0-SNAPSHOT-jar-with-dependencies.jar
hibench.hive.dir.name.input	Input
hibench.hive.dir.name.ouput	Output
hibench.hive.home	/home/hduser/HiBench/src/hivebench/target/hive-0.12.0-bin
hibench.hive.release	hive-0.12.0-bin
hibench.hivebench.template.dir	/home/hduser/HiBench/src/hivebench/hive_template
hibench.kmeans.dir.name.input	Input
hibench.kmeans.dir.name.output	Output
hibench.mahout.home	/home/hduser/HiBench/src/mahout/target/mahout-distribution-0.9
hibench.mahout.release	mahout-distribution-0.9
hibench.mahout.release.apache	mahout-distribution-0.9
hibench.mahout.release.cdh4	mahout-0.7-cdh4.7.1
hibench.mahout.release.cdh5	mahout-0.9-cdh5.1.0
hibench.mahout.release.hdp	mahout-distribution-0.9
hibench.nutch.dir.name.input	Input
hibench.nutch.dir.name.output	Output
hibench.nutch.home	/home/hduser/HiBench/src/nutchindexing/target/nutch-1.2
hibench.nutch.nutchindexing.dir	/home/hduser/HiBench/src/nutchindexing/
hibench.nutch.release	nutch-1.2
hibench.pagerank.dir.name.input	Input
hibench.pagerank.dir.name.output	Output
hibench.pagerank.pegasus.dir	/home/hduser/HiBench/src/pegasus/target/pegasus-2.0-SNAPSHOT.jar
hibench.randomtextwriter.bytestotal.hadoop1.name	test.randomtextwrite.total_bytes
hibench.randomtextwriter.bytestotal.hadoop2.name	mapreduce.randomtextwriter.totalbytes
hibench.randomtextwriter.bytestotal.name	mapreduce.randomtextwriter.totalbytes
hibench.report.dir	/home/hduser/HiBench/report
hibench.report.formats	"%-12s %-10s %-8s %-20s %-20s %-20s %-20s\n"
hibench.report.name	hibench.report
hibench.spark.master	local[1]
hibench.sparkbench.jar	/home/hduser/HiBench/src/sparkbench/target/sparkbench-5.0-SNAPSHOT-MR2-spark1-jar-with-dependencies.jar
hibench.sparkbench.python.dir	/home/hduser/HiBench/src/sparkbench/src/main/python
hibench.workload.compress.datatools.options	
hibench.workload.compress.disable.datatools.options	
hibench.workload.compress.disable.hive.options	
hibench.workload.compress.disable.kmeans_gen.options	"-compress false"
hibench.workload.compress.disable.options	"-D mapreduce.output.fileoutputformat.compress=false"
hibench.workload.compress.enable.datatools.options	"-c org.apache.hadoop.io.compress.SnappyCodec"
hibench.workload.compress.enable.hive.options	set hive.exec.compress.output=true; set mapreduce.jobtracker.address=ignorethis; set hive.exec.show.job.failure.debug.info=false; set mapreduce.map.output.compress.codec=true; set mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec; set mapreduce.output.fileoutputformat.compress=true; set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.SnappyCodec; set mapreduce.output.fileoutputformat.compress.type=BLOCK;
hibench.workload.compress.enable.kmeans_gen.options	"-compress true -compressCodec org.apache.hadoop.io.compress.SnappyCodec -compressType BLOCK"
hibench.workload.compress.enable.options	"-D mapreduce.map.output.compress=true -D mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec -D mapreduce.output.fileoutputformat.compress=true -D mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.SnappyCodec -D mapreduce.output.fileoutputformat.compress.type=BLOCK"
hibench.workload.compress.hive.hadoop1.options	set mapreduce.output.fileoutputformat.compress=true; set mapreduce.output.fileoutputformat.compress.type=BLOCK; set mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec;
hibench.workload.compress.hive.hadoop2.options	set mapreduce.jobtracker.address=ignorethis; set hive.exec.show.job.failure.debug.info=false; set mapreduce.map.output.compress.codec=true; set mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec; set mapreduce.output.fileoutputformat.compress=true; set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.SnappyCodec; set mapreduce.output.fileoutputformat.compress.type=BLOCK;
hibench.workload.compress.hive.options	""
hibench.workload.compress.kmeans_gen.options	"-compress false"
hibench.workload.compress.options	"-D mapreduce.output.fileoutputformat.compress=false"
hibench.workload.dir.name.compress_disable.input	Input
hibench.workload.dir.name.compress_disable.output	Output
hibench.workload.dir.name.compress_enable.input	Input-comp-snappy
hibench.workload.dir.name.compress_enable.output	Output-comp-snappy
hibench.workload.dir.name.input	Input
hibench.workload.dir.name.output	Output
hibench.yarn.driver.memory	4G
hibench.yarn.executor.memory	4G
sparkbench.codec.disable.options	None
sparkbench.codec.enable.options	org.apache.hadoop.io.compress.SnappyCodec
sparkbench.codec.selection	None
sparkbench.inputformat	Sequence
sparkbench.inputformat.codec	None
sparkbench.outputformat	Sequence
sparkbench.outputformat.codec	None

# Source: /home/hduser/HiBench/conf/01-default-streamingbench.conf
hibench.streamingbench.app	micro-sketch
hibench.streamingbench.batch_interval	10
hibench.streamingbench.broker_list_with_quote	"HOSTNAME:HOSTPORT"
hibench.streamingbench.checkpoint_path	
hibench.streamingbench.consumer_group	HiBench
hibench.streamingbench.copies	2
hibench.streamingbench.datagen.dir	hdfs://master:54310/HiBench/Streaming
hibench.streamingbench.datagen.jar	/home/hduser/HiBench/src/streambench/datagen/target/datagen-0.0.1-jar-with-dependencies.jar
hibench.streamingbench.debug	false
hibench.streamingbench.direct_mode	true
hibench.streamingbench.field_index	1
hibench.streamingbench.jars	/home/hduser/HiBench/src/streambench/sparkbench/target/streaming-bench-spark_0.1-5.0-SNAPSHOT-spark1-jar-with-dependencies.jar
hibench.streamingbench.pattern	the
hibench.streamingbench.prepare.mode	periodic
hibench.streamingbench.prepare.periodic.intervalSpan	5000
hibench.streamingbench.prepare.periodic.recordPerInterval	600000
hibench.streamingbench.prepare.periodic.totalRound	100
hibench.streamingbench.prepare.push.records	900000000
hibench.streamingbench.prepare.textdataset_recordsize_factor	
hibench.streamingbench.prob	0.1
hibench.streamingbench.receiver_nodes	4
hibench.streamingbench.record_count	900000000
hibench.streamingbench.separator	\\s+
hibench.streamingbench.sparkbench.jar	/home/hduser/HiBench/src/streambench/sparkbench/target/streaming-bench-spark_0.1-5.0-SNAPSHOT-spark1-jar-with-dependencies.jar
hibench.streamingbench.storm.ackon	true
hibench.streamingbench.storm.bin	/PATH/TO/STORM/HOME/bin
hibench.streamingbench.storm.bolt_threads	12
hibench.streamingbench.storm.nimbusAPIPort	6627
hibench.streamingbench.storm.nimbusContactInterval	10
hibench.streamingbench.storm.read_from_start	true
hibench.streamingbench.storm.spout_threads	12
hibench.streamingbench.storm.worker_count	12
hibench.streamingbench.stormbench.jar	/home/hduser/HiBench/src/streambench/stormbench/target/streaming-bench-storm-0.1-SNAPSHOT-jar-with-dependencies.jar
hibench.streamingbench.testWAL	false
hibench.streamingbench.topic_name	identity
hibench.streamingbench.zkhelper.jar	/home/hduser/HiBench/src/streambench/zkHelper/target/streaming-bench-zkhelper-0.1-SNAPSHOT-jar-with-dependencies.jar

# Source: /home/hduser/HiBench/conf/10-data-scale-profile.conf
hibench.aggregation.bigdata.pages	100000000
hibench.aggregation.bigdata.uservisits	1000000000
hibench.aggregation.gigantic.pages	12000000
hibench.aggregation.gigantic.uservisits	100000000
hibench.aggregation.huge.pages	1200000
hibench.aggregation.huge.uservisits	10000000
hibench.aggregation.large.pages	120000
hibench.aggregation.large.uservisits	1000000
hibench.aggregation.small.pages	12000
hibench.aggregation.small.uservisits	100000
hibench.aggregation.tiny.pages	120
hibench.aggregation.tiny.uservisits	1000
hibench.bayes.bigdata.classes	20000
hibench.bayes.bigdata.ngrams	2
hibench.bayes.bigdata.pages	20000000
hibench.bayes.gigantic.classes	100
hibench.bayes.gigantic.ngrams	2
hibench.bayes.gigantic.pages	1000000
hibench.bayes.huge.classes	100
hibench.bayes.huge.ngrams	2
hibench.bayes.huge.pages	500000
hibench.bayes.large.classes	100
hibench.bayes.large.ngrams	2
hibench.bayes.large.pages	100000
hibench.bayes.small.classes	100
hibench.bayes.small.ngrams	2
hibench.bayes.small.pages	30000
hibench.bayes.tiny.classes	10
hibench.bayes.tiny.ngrams	1
hibench.bayes.tiny.pages	25000
hibench.dfsioe.bigdata.read.file_size	1000
hibench.dfsioe.bigdata.read.number_of_files	2048
hibench.dfsioe.bigdata.write.file_size	1000
hibench.dfsioe.bigdata.write.number_of_files	2048
hibench.dfsioe.gigantic.read.file_size	400
hibench.dfsioe.gigantic.read.number_of_files	512
hibench.dfsioe.gigantic.write.file_size	400
hibench.dfsioe.gigantic.write.number_of_files	512
hibench.dfsioe.huge.read.file_size	100
hibench.dfsioe.huge.read.number_of_files	256
hibench.dfsioe.huge.write.file_size	100
hibench.dfsioe.huge.write.number_of_files	256
hibench.dfsioe.large.read.file_size	10
hibench.dfsioe.large.read.number_of_files	64
hibench.dfsioe.large.write.file_size	10
hibench.dfsioe.large.write.number_of_files	64
hibench.dfsioe.small.read.file_size	10
hibench.dfsioe.small.read.number_of_files	32
hibench.dfsioe.small.write.file_size	10
hibench.dfsioe.small.write.number_of_files	32
hibench.dfsioe.tiny.read.file_size	1
hibench.dfsioe.tiny.read.number_of_files	16
hibench.dfsioe.tiny.write.file_size	1
hibench.dfsioe.tiny.write.number_of_files	16
hibench.join.bigdata.pages	120000000
hibench.join.bigdata.uservisits	5000000000
hibench.join.gigantic.pages	12000000
hibench.join.gigantic.uservisits	100000000
hibench.join.huge.pages	1200000
hibench.join.huge.uservisits	10000000
hibench.join.large.pages	120000
hibench.join.large.uservisits	1000000
hibench.join.small.pages	12000
hibench.join.small.uservisits	100000
hibench.join.tiny.pages	120
hibench.join.tiny.uservisits	1000
hibench.kmeans.bigdata.convergedist	0.5
hibench.kmeans.bigdata.dimensions	20
hibench.kmeans.bigdata.k	10
hibench.kmeans.bigdata.max_iteration	10
hibench.kmeans.bigdata.num_of_clusters	5
hibench.kmeans.bigdata.num_of_samples	1200000000
hibench.kmeans.bigdata.samples_per_inputfile	40000000
hibench.kmeans.gigantic.convergedist	0.5
hibench.kmeans.gigantic.dimensions	20
hibench.kmeans.gigantic.k	10
hibench.kmeans.gigantic.max_iteration	5
hibench.kmeans.gigantic.num_of_clusters	5
hibench.kmeans.gigantic.num_of_samples	200000000
hibench.kmeans.gigantic.samples_per_inputfile	40000000
hibench.kmeans.huge.convergedist	0.5
hibench.kmeans.huge.dimensions	20
hibench.kmeans.huge.k	10
hibench.kmeans.huge.max_iteration	5
hibench.kmeans.huge.num_of_clusters	5
hibench.kmeans.huge.num_of_samples	100000000
hibench.kmeans.huge.samples_per_inputfile	20000000
hibench.kmeans.large.convergedist	0.5
hibench.kmeans.large.dimensions	20
hibench.kmeans.large.k	10
hibench.kmeans.large.max_iteration	5
hibench.kmeans.large.num_of_clusters	5
hibench.kmeans.large.num_of_samples	20000000
hibench.kmeans.large.samples_per_inputfile	4000000
hibench.kmeans.small.convergedist	0.5
hibench.kmeans.small.dimensions	20
hibench.kmeans.small.k	10
hibench.kmeans.small.max_iteration	5
hibench.kmeans.small.num_of_clusters	5
hibench.kmeans.small.num_of_samples	3000000
hibench.kmeans.small.samples_per_inputfile	600000
hibench.kmeans.tiny.convergedist	0.5
hibench.kmeans.tiny.dimensions	3
hibench.kmeans.tiny.k	10
hibench.kmeans.tiny.max_iteration	5
hibench.kmeans.tiny.num_of_clusters	5
hibench.kmeans.tiny.num_of_samples	30000
hibench.kmeans.tiny.samples_per_inputfile	6000
hibench.nutch.bigdata.pages	100000000000
hibench.nutch.gigantic.pages	100000000000
hibench.nutch.huge.pages	10000000000
hibench.nutch.large.pages	1000000000
hibench.nutch.small.pages	1000000
hibench.nutch.tiny.pages	25000
hibench.pagerank.bigdata.block	0
hibench.pagerank.bigdata.block_width	16
hibench.pagerank.bigdata.num_iterations	3
hibench.pagerank.bigdata.pages	30000000
hibench.pagerank.gigantic.block	0
hibench.pagerank.gigantic.block_width	16
hibench.pagerank.gigantic.num_iterations	3
hibench.pagerank.gigantic.pages	50000000
hibench.pagerank.huge.block	0
hibench.pagerank.huge.block_width	16
hibench.pagerank.huge.num_iterations	3
hibench.pagerank.huge.pages	5000000
hibench.pagerank.large.block	0
hibench.pagerank.large.block_width	16
hibench.pagerank.large.num_iterations	3
hibench.pagerank.large.pages	500000
hibench.pagerank.small.block	0
hibench.pagerank.small.block_width	16
hibench.pagerank.small.num_iterations	3
hibench.pagerank.small.pages	5000
hibench.pagerank.tiny.block	0
hibench.pagerank.tiny.block_width	16
hibench.pagerank.tiny.num_iterations	1
hibench.pagerank.tiny.pages	50
hibench.scan.bigdata.pages	10000000
hibench.scan.bigdata.uservisits	2000000000
hibench.scan.gigantic.pages	12000000
hibench.scan.gigantic.uservisits	100000000
hibench.scan.huge.pages	1200000
hibench.scan.huge.uservisits	10000000
hibench.scan.large.pages	120000
hibench.scan.large.uservisits	1000000
hibench.scan.small.pages	12000
hibench.scan.small.uservisits	100000
hibench.scan.tiny.pages	120
hibench.scan.tiny.uservisits	1000
hibench.sleep.bigdata.mapper.seconds	10
hibench.sleep.bigdata.reducer.seconds	10
hibench.sleep.gigantic.mapper.seconds	90
hibench.sleep.gigantic.reducer.seconds	45
hibench.sleep.huge.mapper.seconds	90
hibench.sleep.huge.reducer.seconds	45
hibench.sleep.large.mapper.seconds	90
hibench.sleep.large.reducer.seconds	45
hibench.sleep.small.mapper.seconds	30
hibench.sleep.small.reducer.seconds	30
hibench.sleep.tiny.mapper.seconds	3
hibench.sleep.tiny.reducer.seconds	3
hibench.sort.bigdata.datasize	300000000000
hibench.sort.gigantic.datasize	32000000000
hibench.sort.huge.datasize	3200000000
hibench.sort.large.datasize	320000000
hibench.sort.small.datasize	3200000
hibench.sort.tiny.datasize	32000
hibench.terasort.bigdata.datasize	6000000000
hibench.terasort.gigantic.datasize	3200000000
hibench.terasort.huge.datasize	320000000
hibench.terasort.large.datasize	32000000
hibench.terasort.small.datasize	3200000
hibench.terasort.tiny.datasize	32000
hibench.wordcount.bigdata.datasize	1600000000000
hibench.wordcount.gigantic.datasize	320000000000
hibench.wordcount.huge.datasize	32000000000
hibench.wordcount.large.datasize	3200000000
hibench.wordcount.small.datasize	320000000
hibench.wordcount.tiny.datasize	32000

# Source: /home/hduser/HiBench/conf/99-user_defined_properties.conf
hibench.compress.codec.profile	snappy
hibench.compress.profile	disable
hibench.default.map.parallelism	12
hibench.default.shuffle.parallelism	6
hibench.hadoop.examples.jar	/home/hduser/hadoop_related/hadoop-examples.jar
hibench.hadoop.home	/usr/local/hadoop
hibench.hadoop.release	apache
hibench.hadoop.version	hadoop2
hibench.hdfs.master	hdfs://master:54310
hibench.scale.profile	large
hibench.spark.home	/PATH/TO/YOUR/SPARK/ROOT
hibench.streamingbench.benchname	identity
hibench.streamingbench.brokerList	HOSTNAME:HOSTPORT
hibench.streamingbench.kafka.home	/PATH/TO/KAFKA/HOME
hibench.streamingbench.partitions	1
hibench.streamingbench.scale.profile	large
hibench.streamingbench.storm.home	/PATH/TO/STORM/HOME
hibench.streamingbench.storm.nimbus	HOSTNAME_TO_STORM_NIMBUS
hibench.streamingbench.zookeeper.host	HOSTNAME:HOSTPORT
hibench.yarn.executor.cores	4
hibench.yarn.executor.num	4

# Source: /home/hduser/HiBench/workloads/wordcount/conf/00-wordcount-default.conf
hibench.wordcount.base_hdfs	hdfs://master:54310/HiBench/Wordcount
hibench.wordcount.datasize	3200000000
hibench.workload.datasize	3200000000
hibench.workload.input	hdfs://master:54310/HiBench/Wordcount/Input
hibench.workload.output	hdfs://master:54310/HiBench/Wordcount/Output

# Source: Inferred by: 'hibench.hadoop.version'
hibench.hadoop.mapper.name	mapreduce.job.maps
hibench.hadoop.reducer.name	mapreduce.job.reduces

# Source: Inferred by: 'hibench.hadoop.version' & 'hibench.hadoop.release'
hibench.hadoop.configure.dir	/usr/local/hadoop/etc/hadoop

# Source: Inferred by: /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient*-tests.jar
hibench.hadoop.examples.test.jar	/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar

# Source: Inferred from relative path of dirname(/home/hduser/HiBench/bin/functions/load-config.py)/../../
hibench.home	/home/hduser/HiBench

# Source: Probed by shell command: ( cd /PATH/TO/YOUR/SPARK/ROOT; mvn help:evaluate -Dexpression=project.version 2> /dev/null | grep -v "INFO" | tail -n 1), value: 1
hibench.spark.version	spark1

# Source: Probed by shell command:'cat /usr/local/hadoop/etc/hadoop/mapred-site.xml | grep "mapreduce.map.java.opts" | awk -F\< '{print $5}' | awk -F\> '{print $NF}''
hibench.dfsioe.map.java_opts	

# Source: Probed by shell command:'cat /usr/local/hadoop/etc/hadoop/mapred-site.xml | grep "mapreduce.reduce.java.opts" | awk -F\< '{print $5}' | awk -F\> '{print $NF}''
hibench.dfsioe.red.java_opts	

# Source: Probed by the evidence of 'hibench.spark.master=local[1]'
hibench.masters.hostnames	''
hibench.slaves.hostnames	'localhost'

# Source: Refer to `hibench.hadoop.examples.test.jar` according to the evidence of `hibench.hadoop.release` and `hibench.hadoop.version`
hibench.sleep.job.jar	/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar

