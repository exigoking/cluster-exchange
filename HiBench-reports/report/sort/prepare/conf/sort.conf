# Source: /home/hduser/HiBench/conf/00-default-properties.conf
BAYES_INPUT=Input
BYTES_TOTAL_NAME=mapreduce.randomtextwriter.totalbytes
COMPRESS_OPT="-D mapreduce.output.fileoutputformat.compress=false"
DATATOOLS=/home/hduser/HiBench/src/autogen/target/autogen-5.0-SNAPSHOT-jar-with-dependencies.jar
DATATOOLS_COMPRESS_OPT=
DATA_HDFS=hdfs://master:54310/HiBench
DEPENDENCY_DIR=/home/hduser/HiBench/src
HADOOP_EXECUTABLE=/usr/local/hadoop/bin/hadoop
HIBENCH_CONF=/home/hduser/HiBench/conf
HIBENCH_PYTHON_PATH=/home/hduser/HiBench/src/sparkbench/src/main/python
HIBENCH_REPORT=/home/hduser/HiBench/report
HIBENCH_REPORT_NAME=hibench.report
HIVEBENCH_TEMPLATE=/home/hduser/HiBench/src/hivebench/hive_template
HIVE_HOME=/home/hduser/HiBench/src/hivebench/target/hive-0.12.0-bin
HIVE_INPUT=Input
HIVE_RELEASE=hive-0.12.0-bin
HIVE_SQL_COMPRESS_OPTS=""
KMEANS_COMPRESS_OPT="-compress false"
MAHOUT_HOME=/home/hduser/HiBench/src/mahout/target/mahout-distribution-0.9
MAHOUT_RELEASE=mahout-distribution-0.9
NUTCH_DIR=/home/hduser/HiBench/src/nutchindexing/
NUTCH_HOME=/home/hduser/HiBench/src/nutchindexing/target/nutch-1.2
NUTCH_INPUT=Input
PAGERANK_INPUT=Input
PEGASUS_JAR=/home/hduser/HiBench/src/pegasus/target/pegasus-2.0-SNAPSHOT.jar
REPORT_COLUMN_FORMATS="%-12s %-10s %-8s %-20s %-20s %-20s %-20s\n"
SPARKBENCH_JAR=/home/hduser/HiBench/src/sparkbench/target/sparkbench-5.0-SNAPSHOT-MR2-spark1-jar-with-dependencies.jar
SPARK_MASTER=local[1]
YARN_DRIVER_MEMORY=4G
YARN_EXECUTOR_MEMORY=4G

# Source: /home/hduser/HiBench/conf/01-default-streamingbench.conf
DATA_GEN_JAR=/home/hduser/HiBench/src/streambench/datagen/target/datagen-0.0.1-jar-with-dependencies.jar
STORM_BIN_HOME=/PATH/TO/STORM/HOME/bin
STREAMBENCH_STORM_JAR=/home/hduser/HiBench/src/streambench/stormbench/target/streaming-bench-storm-0.1-SNAPSHOT-jar-with-dependencies.jar
STREAMINGBENCH_JARS=/home/hduser/HiBench/src/streambench/sparkbench/target/streaming-bench-spark_0.1-5.0-SNAPSHOT-spark1-jar-with-dependencies.jar
STREAMING_CONSUMER_GROUP=HiBench
STREAMING_DATAGEN_MODE=periodic
STREAMING_DATAGEN_RECORDS=900000000
STREAMING_DATA_DIR=hdfs://master:54310/HiBench/Streaming
STREAMING_TOPIC_NAME=identity
STREAMING_ZKHELPER_JAR=/home/hduser/HiBench/src/streambench/zkHelper/target/streaming-bench-zkhelper-0.1-SNAPSHOT-jar-with-dependencies.jar

# Source: /home/hduser/HiBench/conf/20-samza-common.conf
SAMZA_PARTITIONS=1
SAMZA_REPLICATION_FACTOR=1
STREAMING_SAMZA_PACKAGE_HDFS_PATH=hdfs://master:54310/HiBench/Streaming/samza_package/streaming-bench-samza-0.1-SNAPSHOT-dist.tar.gz
STREAMING_SAMZA_PACKAGE_LOCAL_PATH=/home/hduser/HiBench/src/streambench/samzabench/target/streaming-bench-samza-0.1-SNAPSHOT-dist.tar.gz

# Source: /home/hduser/HiBench/conf/30-samza-workloads.conf
STREAMING_SAMZA_DISTINCOUNT_INTERNAL_TOPIC=words
STREAMING_SAMZA_STATISTICS_INTERNAL_TOPIC=numbers
STREAMING_SAMZA_WORDCOUNT_INTERNAL_TOPIC=wordcount-source

# Source: /home/hduser/HiBench/conf/99-user_defined_properties.conf
HADOOP_EXAMPLES_JAR=/home/hduser/hadoop_related/hadoop-examples.jar
HADOOP_HOME=/usr/local/hadoop
HADOOP_RELEASE=apache
HADOOP_VERSION=hadoop2
HDFS_MASTER=hdfs://master:54310
NUM_MAPS=12
NUM_REDS=6
SPARK_HOME=/PATH/TO/YOUR/SPARK/ROOT
STREAMING_BENCHNAME=identity
STREAMING_KAFKA_HOME=/PATH/TO/KAFKA/HOME
STREAMING_PARTITIONS=1
STREAMING_ZKADDR=HOSTNAME:HOSTPORT
YARN_EXECUTOR_CORES=4
YARN_NUM_EXECUTORS=4

# Source: /home/hduser/HiBench/workloads/sort/conf/00-sort-default.conf
DATASIZE=320000000
INPUT_HDFS=hdfs://master:54310/HiBench/Sort/Input
OUTPUT_HDFS=hdfs://master:54310/HiBench/Sort/Output

# Source: Inferred by: 'hibench.hadoop.version'
MAP_CONFIG_NAME=mapreduce.job.maps
REDUCER_CONFIG_NAME=mapreduce.job.reduces

# Source: Inferred by: 'hibench.hadoop.version' & 'hibench.hadoop.release'
HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop

# Source: Inferred from relative path of dirname(/home/hduser/HiBench/bin/functions/load-config.py)/../../
HIBENCH_HOME=/home/hduser/HiBench

# Source: None
BAYES_BASE_HDFS=
BLOCK=
CLASSES=
DIMENSIONS=
HIVE_BASE_HDFS=
INPUT_CLUSTER=
INPUT_SAMPLE=
K=
MAP_SLEEP_TIME=
MAX_ITERATION=
NGRAMS=
NUM_ITERATIONS=
NUM_OF_CLUSTERS=
NUM_OF_SAMPLES=
NUTCH_BASE_HDFS=
PAGERANK_BASE_HDFS=
PAGES=
RD_FILE_SIZE=
RD_NUM_OF_FILES=
RED_SLEEP_TIME=
SAMPLES_PER_INPUTFILE=
SPARK_EXAMPLES_JAR=
STREAMING_DATA1_DIR=
STREAMING_DATA1_LENGTH=
STREAMING_DATA1_NAME=
STREAMING_DATA2_CLUSTER_DIR=
STREAMING_DATA2_SAMPLE_DIR=
STREAMING_DATA_SCALE_FACTOR=
USERVISITS=
WT_FILE_SIZE=
WT_NUM_OF_FILES=

# Source: Probed by shell command: ( cd /PATH/TO/YOUR/SPARK/ROOT; mvn help:evaluate -Dexpression=project.version 2> /dev/null | grep -v "INFO" | tail -n 1), value: 1
SPARK_VERSION=spark1

# Source: Probed by shell command:'cat /usr/local/hadoop/etc/hadoop/mapred-site.xml | grep "mapreduce.map.java.opts" | awk -F\< '{print $5}' | awk -F\> '{print $NF}''
MAP_JAVA_OPTS=

# Source: Probed by shell command:'cat /usr/local/hadoop/etc/hadoop/mapred-site.xml | grep "mapreduce.reduce.java.opts" | awk -F\< '{print $5}' | awk -F\> '{print $NF}''
RED_JAVA_OPTS=

# Source: Probed by the evidence of 'hibench.spark.master=local[1]'
MASTERS=''
SLAVES='localhost'

# Source: Refer to `hibench.hadoop.examples.test.jar` according to the evidence of `hibench.hadoop.release` and `hibench.hadoop.version`
HADOOP_SLEEP_JAR=/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar

# Source: probed by lookup in $PATH: /usr/bin
JAVA_BIN=/usr/bin/java

#Source: add for internal usage
SPARKBENCH_PROPERTIES_FILES=/home/hduser/HiBench/report/sort/prepare/conf/sparkbench/sparkbench.conf
SPARK_PROP_CONF=/home/hduser/HiBench/report/sort/prepare/conf/sparkbench/spark.conf
SAMZA_PROP_CONF=/home/hduser/HiBench/report/sort/prepare/conf/sparkbench/samza.conf
WORKLOAD_RESULT_FOLDER=/home/hduser/HiBench/report/sort/prepare/conf/..
HIBENCH_WORKLOAD_CONF=/home/hduser/HiBench/report/sort/prepare/conf/sort.conf
export HADOOP_EXECUTABLE
export HADOOP_CONF_DIR
